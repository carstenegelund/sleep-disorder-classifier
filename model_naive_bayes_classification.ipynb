{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; letter-spacing: 2px; color:#F5F5DC; font-size:140%; text-align:left; max-width: 1050px; padding: 10px; border-bottom: 3px solid #D2B48C\"> Naive Bayes Classification</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom classes, functions and variables. Reload file in to memory on cell excution.\n",
    "import importlib\n",
    "import settings\n",
    "importlib.reload(settings)\n",
    "\n",
    "# import data frameworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # for custom classes\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "\n",
    "# import others\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import data from initial EDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df loaded\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(settings.DATA_EDA_DIR, settings.DATA_EDA_FILE), sep=\",\")\n",
    "if len(df) > 0:\n",
    "    print(\"df loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Binning numerical features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique Values    [25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59]\n",
       "Name: Age Bin, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin age to new column and drop original column\n",
    "df.loc[:,'Age Bin'] = pd.cut(df.loc[:,'Age'], \n",
    "[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, float('inf')], \n",
    "labels=['0-4', '5-9', '10-15', '10-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', '80-84', '85-89', '90-94', '95-99', '>100']).astype(\"object\")\n",
    "df = df.drop(\"Age\", axis=1)\n",
    "# check new values in consolidated column\n",
    "settings.examine_values(df).loc[\"Age Bin\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique Values    [6.0-6.4, 5.5-5.9, 7.5-7.9, 7.0-7.4, 6.5-6.9, 8.0-8.4]\n",
       "Name: Sleep Duration Bin, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin sleep duration to new column and drop original column\n",
    "df.loc[:,'Sleep Duration Bin'] = pd.cut(df.loc[:,'Sleep Duration'], \n",
    "[0, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10, float('inf')], \n",
    "labels=['<4', '4.0-4.4', '4.5-4.9', '5.0-5.4', '5.5-5.9', '6.0-6.4', '6.5-6.9', '7.0-7.4', '7.5-7.9', '8.0-8.4', '8.5-8.9', '9.0-9.4', '9.5-9.9', '>10']).astype(\"object\")\n",
    "df = df.drop(\"Sleep Duration\", axis=1)\n",
    "# check new values in consolidated column\n",
    "settings.examine_values(df).loc[\"Sleep Duration Bin\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique Values    [40-49, 50-59, 20-29, 30-39, 70-79, 60-69, 80-89]\n",
       "Name: Physical Activity Level Bin, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin physical activity level to new column and drop original column\n",
    "df.loc[:,'Physical Activity Level Bin'] = pd.cut(df.loc[:,'Physical Activity Level'], \n",
    "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, float('inf')], \n",
    "labels=['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-99', '>100']).astype(\"object\")\n",
    "df = df.drop(\"Physical Activity Level\", axis=1)\n",
    "# check new values in consolidated column\n",
    "settings.examine_values(df).loc[\"Physical Activity Level Bin\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique Values    [75-79, 70-74, 80-84, 65-69, 60-64, 85-89]\n",
       "Name: Heart Rate Bin, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin heart rate to new column and drop original column\n",
    "df.loc[:,'Heart Rate Bin'] = pd.cut(df.loc[:,'Heart Rate'], \n",
    "[0, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, float('inf')], \n",
    "labels=['<40', '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', '80-84', '85-89', '90-94', '95-99', '>100']).astype(\"object\")\n",
    "df = df.drop(\"Heart Rate\", axis=1)\n",
    "# check new values in consolidated column\n",
    "settings.examine_values(df).loc[\"Heart Rate Bin\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique Values    [4000-4499, 9500-9999, <3000, 3000-3499, 7500-7999, 3500-3999, 6500-6999, 4500-4999, 5000-5499, 5500-5999, 7000-7499, 6000-6499]\n",
       "Name: Daily Steps Bin, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin daily steps to new column and drop original column\n",
    "df.loc[:,'Daily Steps Bin'] = pd.cut(df.loc[:,'Daily Steps'], \n",
    "[0, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 100000, float('inf')], \n",
    "labels=['<3000', '3000-3499', '3500-3999', '4000-4499', '4500-4999', '5000-5499', '5500-5999', '6000-6499', '6500-6999', '7000-7499', '7500-7999', '8000-8499', '8500-8999', '9000-9499', '9500-9999', '>100']).astype(\"object\")\n",
    "df = df.drop(\"Daily Steps\", axis=1)\n",
    "# check new values in consolidated column\n",
    "settings.examine_values(df).loc[\"Daily Steps Bin\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Split data and prepare labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FEATURES = ['Gender', 'Occupation', 'Stress Level', 'BMI Category', 'Blood Pressure Category', 'Age Bin',\n",
    "       'Sleep Duration Bin', 'Quality of Sleep', 'Physical Activity Level Bin', 'Heart Rate Bin', 'Daily Steps Bin']\n",
    "\n",
    "X = df[ALL_FEATURES]\n",
    "y = df[settings.LABEL]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode y vector \n",
    "map = {\"None\":0, \"Sleep Apnea\":1, \"Insomnia\":2}\n",
    "# apply mapping function\n",
    "settings.column_mapper(y_train, \"Sleep Disorder\", map)\n",
    "settings.column_mapper(y_test, \"Sleep Disorder\", map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape labels to 1-D array (vector) \n",
    "y_train, y_test = y_train.values.reshape(-1), y_test.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 261 entries, 19 to 95\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Gender                       261 non-null    object\n",
      " 1   Occupation                   261 non-null    object\n",
      " 2   Stress Level                 261 non-null    int64 \n",
      " 3   BMI Category                 261 non-null    object\n",
      " 4   Blood Pressure Category      261 non-null    object\n",
      " 5   Age Bin                      261 non-null    object\n",
      " 6   Sleep Duration Bin           261 non-null    object\n",
      " 7   Quality of Sleep             261 non-null    int64 \n",
      " 8   Physical Activity Level Bin  261 non-null    object\n",
      " 9   Heart Rate Bin               261 non-null    object\n",
      " 10  Daily Steps Bin              261 non-null    object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 24.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess steps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer for label encoding\n",
    "column_trans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('labelencoder', LabelEncoder(), X_train.select_dtypes(include=['object']).columns)  # slice(None) represents all columns\n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# # Convert to df as a sense check. Use only for interpretibility before using for pipeline. \n",
    "# transformed_X_train_df = settings.convert_transformed_features_to_df(column_trans, column_trans.fit_transform(X_train))\n",
    "# transformed_X_test_df = settings.convert_transformed_features_to_df(column_trans, column_trans.transform(X_test))\n",
    "\n",
    "# Check ohe and scaled datasets\n",
    "# display(\"train: check for dummy encoded columns and scaled values (mean 0 and std 1)\",transformed_X_train_df.shape, transformed_X_train_df.describe().loc[[\"mean\", \"std\"],:])\n",
    "# display(\"test: check for same dummy encoded columns and scaled values (mean close to 0 and std close to 1)\",transformed_X_test_df.shape, transformed_X_test_df.describe().loc[[\"mean\", \"std\"],:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
